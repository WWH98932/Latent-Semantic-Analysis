{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### First I used Sublime Text to re-encode the text file as \"utf-8\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'in': 6\n",
      "'the': 24\n",
      "'first': 1\n",
      "'week's': 1\n",
      "'class': 7\n",
      "'we': 7\n",
      "'introduce': 1\n",
      "'ourselves': 1\n",
      "'and': 17\n",
      "'reason': 1\n",
      "'of': 13\n",
      "'picking': 1\n",
      "'this': 4\n",
      "'after': 3\n",
      "'that': 5\n",
      "'dr': 2\n",
      "'rashed': 2\n",
      "'iqbal': 2\n",
      "'introduced': 1\n",
      "'main': 1\n",
      "'contents': 1\n",
      "'i': 9\n",
      "'felt': 1\n",
      "'really': 5\n",
      "'interested': 2\n",
      "'job': 1\n",
      "'market': 2\n",
      "'how': 1\n",
      "'to': 5\n",
      "'become': 2\n",
      "'a': 7\n",
      "'data': 7\n",
      "'scientist': 2\n",
      "'also': 1\n",
      "'found': 3\n",
      "'examples': 1\n",
      "'case': 1\n",
      "'studies': 1\n",
      "'would': 2\n",
      "'be': 2\n",
      "'interesting': 3\n",
      "'help': 2\n",
      "'me': 1\n",
      "'lot': 2\n",
      "'learn': 1\n",
      "'python': 2\n",
      "'then': 1\n",
      "'told': 1\n",
      "'us': 2\n",
      "'something': 1\n",
      "'about': 2\n",
      "'for': 2\n",
      "'science': 4\n",
      "'professionals': 1\n",
      "'he': 2\n",
      "'gave': 1\n",
      "'brief': 2\n",
      "'introduction': 3\n",
      "'morgan': 1\n",
      "'stanley': 1\n",
      "'ironwood': 1\n",
      "'airbnb': 1\n",
      "'discussed': 2\n",
      "'relationship': 1\n",
      "'between': 3\n",
      "'economy': 1\n",
      "'regard': 1\n",
      "'demand': 1\n",
      "'as': 3\n",
      "'most': 1\n",
      "'part': 1\n",
      "'keep': 1\n",
      "'believing': 1\n",
      "'truth': 2\n",
      "'world': 1\n",
      "'our': 2\n",
      "'society': 2\n",
      "'is': 1\n",
      "'behind': 1\n",
      "'which': 1\n",
      "'can': 3\n",
      "'hardly': 1\n",
      "'measure': 1\n",
      "'understand': 2\n",
      "'before': 2\n",
      "'use': 1\n",
      "'analyze': 1\n",
      "'programs': 1\n",
      "'with': 3\n",
      "'r': 1\n",
      "'other': 1\n",
      "'computer': 2\n",
      "'languages': 1\n",
      "'discover': 1\n",
      "'grow': 1\n",
      "'nowadays': 1\n",
      "'out': 2\n",
      "'my': 1\n",
      "'project': 1\n",
      "'group': 1\n",
      "'began': 1\n",
      "'activity': 1\n",
      "'determining': 1\n",
      "'application': 2\n",
      "'measuring': 1\n",
      "'similarity': 1\n",
      "'different': 1\n",
      "'people': 1\n",
      "'progression': 1\n",
      "'helpful': 1\n",
      "'discuss': 1\n",
      "'topics': 1\n",
      "'others': 1\n",
      "'their': 1\n",
      "'unique': 1\n",
      "'thoughts': 1\n",
      "'are': 1\n",
      "'dividing': 1\n",
      "'students': 2\n",
      "'into': 1\n",
      "'groups': 1\n",
      "'four': 1\n",
      "'have': 2\n",
      "'information': 1\n",
      "'on': 1\n",
      "'students'': 1\n",
      "'gpa': 1\n",
      "'last': 1\n",
      "'semester': 1\n",
      "'graduate': 1\n",
      "'courses': 1\n",
      "'they': 1\n",
      "'taken': 1\n",
      "'need': 1\n",
      "'formula': 1\n",
      "'evaluate': 1\n",
      "'difference': 1\n",
      "'skill': 1\n",
      "'levels': 1\n",
      "'finish': 1\n",
      "'work': 1\n",
      "'together': 1\n",
      "'modules': 1\n",
      "'course': 1\n",
      "'look': 1\n",
      "'forward': 1\n",
      "'machine': 1\n",
      "'learning': 2\n",
      "'deep': 1\n",
      "'will': 1\n",
      "'future': 2\n",
      "'know': 1\n",
      "'nothing': 1\n",
      "'sentiment': 1\n",
      "'analysis': 1\n",
      "'visualization': 1\n",
      "'now': 1\n",
      "'i'm': 1\n",
      "'these': 1\n",
      "'two': 1\n",
      "'area': 1\n",
      "'feel': 1\n",
      "'it': 1\n",
      "'significant': 1\n",
      "            tf1  tf2  tf3  tf4  tf5  tf6  tf7  tf8  tf9  tf10  tf11\n",
      "&             0    0    1    0    0    0    0    0    0     0     0\n",
      "-             0    0    0    0    2    2    0    0    1     0     0\n",
      "1             0    0    1    0    0    0    1    0    0     0     0\n",
      "10            0    0    0    0    0    0    0    0    0     0     1\n",
      "15            1    0    0    0    1    0    0    0    0     0     0\n",
      "190000        1    0    0    0    1    0    0    0    0     0     0\n",
      "2             0    0    0    0    0    0    1    0    0     0     0\n",
      "2018          1    0    0    0    1    0    0    0    0     0     0\n",
      "21st          0    0    0    0    0    0    1    0    0     0     0\n",
      "25            0    2    0    0    0    0    0    0    0     0     0\n",
      "3             0    0    0    0    0    0    1    0    0     0     0\n",
      "50            0    1    0    0    0    0    0    0    0     0     0\n",
      "a            10   10    8    7   13    8   10    9    7    13     3\n",
      "abandon       0    0    0    0    0    0    0    0    0     1     0\n",
      "abilities     2    0    0    0    0    0    0    0    0     0     0\n",
      "about         0    1    1    2    0    2    4    3    2     0     2\n",
      "academic      0    0    0    0    1    0    0    0    0     0     0\n",
      "accomplish    0    0    0    0    0    0    0    0    0     1     0\n",
      "according     0    1    0    0    1    0    0    0    0     0     0\n",
      "achieve       0    0    0    0    0    0    0    1    0     0     0\n",
      "acquire       0    0    0    0    0    1    0    1    0     0     0\n",
      "actionable    1    0    0    0    1    0    0    0    0     0     0\n",
      "activities    0    1    0    0    0    0    0    0    0     0     0\n",
      "activity      0    1    0    1    0    2    0    0    1     1     0\n",
      "actual        0    1    1    0    0    0    0    0    0     0     0\n",
      "actually      0    1    0    0    1    0    2    0    1     0     0\n",
      "addition      0    0    0    0    0    0    0    1    0     0     0\n",
      "ads           0    0    0    0    0    0    1    0    0     0     0\n",
      "advising      1    0    0    0    0    0    0    0    0     0     0\n",
      "affected      0    0    0    0    0    0    0    0    1     0     0\n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...\n",
      "weeks         0    1    0    0    0    0    0    0    0     0     1\n",
      "weigh         0    0    1    0    0    0    0    0    0     0     0\n",
      "well          2    1    0    0    0    0    0    1    2     0     0\n",
      "went          0    0    0    0    0    0    0    0    0     2     0\n",
      "were          0    1    1    0    1    1    0    1    2     0     0\n",
      "what          2    0    1    0    2    3    2    1    1     3     0\n",
      "what's        0    0    0    0    0    1    1    0    0     0     0\n",
      "when          0    0    0    0    0    0    0    2    1     1     0\n",
      "where         0    0    0    0    0    0    0    0    0     0     1\n",
      "whether       0    0    0    0    0    0    0    0    2     0     0\n",
      "which         0    3    1    1    2    0    1    0    1     3     0\n",
      "while         0    0    0    0    0    1    1    0    0     0     0\n",
      "who           1    0    1    0    1    0    1    0    2     3     2\n",
      "why           1    0    0    0    1    1    0    0    0     3     0\n",
      "wide          0    1    0    0    0    0    0    0    0     0     0\n",
      "will          2    2    2    1    1    0    0    2    1     0     0\n",
      "wish          0    0    0    0    0    1    0    0    0     0     0\n",
      "with          4    1    1    3    2    3    0    3    6     2     1\n",
      "without       0    0    0    0    0    0    0    0    1     0     0\n",
      "word          0    0    0    0    0    0    1    0    0     0     0\n",
      "work          0    1    1    1    0    1    0    1    0     0     1\n",
      "working       1    0    0    0    0    1    0    0    1     0     0\n",
      "works         0    0    0    0    0    0    0    0    0     0     1\n",
      "world         1    2    0    1    0    1    0    0    0     1     1\n",
      "would         0    0    1    2    5    0    0    2    0     0     5\n",
      "write         0    0    0    0    1    0    0    0    0     0     0\n",
      "writing       0    0    0    0    1    0    0    0    0     0     0\n",
      "wrong         0    0    0    0    0    1    0    0    0     0     0\n",
      "years         0    1    0    0    0    0    0    0    0     0     0\n",
      "you           0    0    0    0    3    2    0    3    1     0     0\n",
      "\n",
      "[971 rows x 11 columns]\n",
      "[[0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "with open('LSA.txt', 'r') as f:\n",
    "    data = f.read().lower()\n",
    "    clean_data = re.sub(r'[,\"./()?:!]', '', data)\n",
    "    result = {}\n",
    "    for line in clean_data.splitlines():\n",
    "        if not line:\n",
    "            continue  # skip blank lines\n",
    "        elif line.startswith('xxx'):\n",
    "            doc_num = 'tf{}'.format(line[3:])  # skip the \"XXX\" and name the docs as \"tf1 - tf11\"\n",
    "        else:\n",
    "            result[doc_num] = collections.Counter(line.split())\n",
    " \n",
    "    list(result.keys())\n",
    "\n",
    "for k, v in list(result['tf4'].items()):  # select any dicts from result to see if it is correct\n",
    "    print(\"'{}': {}\".format(k, v))\n",
    "    \n",
    "df = pd.DataFrame(result, columns = list(result.keys()))\n",
    "df = df.fillna(0).astype(int)  # change NaNs to 0 and only take integers\n",
    "\n",
    "print(df)  # see the TD - Term Frequency data frame we get\n",
    "\n",
    "df.to_csv('tdm.txt', index=True, sep='\\t', header=True, mode = 'a')  # output as text file\n",
    "\n",
    "np_df = df.as_matrix()  # if we wanna turn it into a numpy matrix\n",
    "print(np_df)\n",
    "\n",
    "def returnTermFrequency (term, document):  #  a program of \"returnTermFrequency\"\n",
    "    TermFrequency = df.loc[str(term), str(document)]\n",
    "    print(TermFrequency)\n",
    "    \n",
    "returnTermFrequency ('will', 'tf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 idf\n",
      "&           2.397895\n",
      "-           1.299283\n",
      "1           1.704748\n",
      "10          2.397895\n",
      "15          1.704748\n",
      "190000      1.704748\n",
      "2           2.397895\n",
      "2018        1.704748\n",
      "21st        2.397895\n",
      "25          2.397895\n",
      "3           2.397895\n",
      "50          2.397895\n",
      "a           0.000000\n",
      "abandon     2.397895\n",
      "abilities   2.397895\n",
      "about       0.318454\n",
      "academic    2.397895\n",
      "accomplish  2.397895\n",
      "according   1.704748\n",
      "achieve     2.397895\n",
      "acquire     1.704748\n",
      "actionable  1.704748\n",
      "activities  2.397895\n",
      "activity    0.788457\n",
      "actual      1.704748\n",
      "actually    1.011601\n",
      "addition    2.397895\n",
      "ads         2.397895\n",
      "advising    2.397895\n",
      "affected    2.397895\n",
      "...              ...\n",
      "weeks       1.704748\n",
      "weigh       2.397895\n",
      "well        1.011601\n",
      "went        2.397895\n",
      "were        0.606136\n",
      "what        0.318454\n",
      "what's      1.704748\n",
      "when        1.299283\n",
      "where       2.397895\n",
      "whether     2.397895\n",
      "which       0.451985\n",
      "while       1.704748\n",
      "who         0.451985\n",
      "why         1.011601\n",
      "wide        2.397895\n",
      "will        0.451985\n",
      "wish        2.397895\n",
      "with        0.095310\n",
      "without     2.397895\n",
      "word        2.397895\n",
      "work        0.606136\n",
      "working     1.299283\n",
      "works       2.397895\n",
      "world       0.606136\n",
      "would       0.788457\n",
      "write       2.397895\n",
      "writing     2.397895\n",
      "wrong       2.397895\n",
      "years       2.397895\n",
      "you         1.011601\n",
      "\n",
      "[971 rows x 1 columns]\n",
      "                 tf1       tf2       tf3       tf4       tf5       tf6  \\\n",
      "&           0.000000  0.000000  2.397895  0.000000  0.000000  0.000000   \n",
      "-           0.000000  0.000000  0.000000  0.000000  2.598566  2.598566   \n",
      "1           0.000000  0.000000  1.704748  0.000000  0.000000  0.000000   \n",
      "10          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "15          1.704748  0.000000  0.000000  0.000000  1.704748  0.000000   \n",
      "190000      1.704748  0.000000  0.000000  0.000000  1.704748  0.000000   \n",
      "2           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2018        1.704748  0.000000  0.000000  0.000000  1.704748  0.000000   \n",
      "21st        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "25          0.000000  4.795791  0.000000  0.000000  0.000000  0.000000   \n",
      "3           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "50          0.000000  2.397895  0.000000  0.000000  0.000000  0.000000   \n",
      "a           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "abandon     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "abilities   4.795791  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "about       0.000000  0.318454  0.318454  0.636907  0.000000  0.636907   \n",
      "academic    0.000000  0.000000  0.000000  0.000000  2.397895  0.000000   \n",
      "accomplish  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "according   0.000000  1.704748  0.000000  0.000000  1.704748  0.000000   \n",
      "achieve     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "acquire     0.000000  0.000000  0.000000  0.000000  0.000000  1.704748   \n",
      "actionable  1.704748  0.000000  0.000000  0.000000  1.704748  0.000000   \n",
      "activities  0.000000  2.397895  0.000000  0.000000  0.000000  0.000000   \n",
      "activity    0.000000  0.788457  0.000000  0.788457  0.000000  1.576915   \n",
      "actual      0.000000  1.704748  1.704748  0.000000  0.000000  0.000000   \n",
      "actually    0.000000  1.011601  0.000000  0.000000  1.011601  0.000000   \n",
      "addition    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "ads         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "advising    2.397895  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "affected    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "weeks       0.000000  1.704748  0.000000  0.000000  0.000000  0.000000   \n",
      "weigh       0.000000  0.000000  2.397895  0.000000  0.000000  0.000000   \n",
      "well        2.023202  1.011601  0.000000  0.000000  0.000000  0.000000   \n",
      "went        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "were        0.000000  0.606136  0.606136  0.000000  0.606136  0.606136   \n",
      "what        0.636907  0.000000  0.318454  0.000000  0.636907  0.955361   \n",
      "what's      0.000000  0.000000  0.000000  0.000000  0.000000  1.704748   \n",
      "when        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "whether     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "which       0.000000  1.355955  0.451985  0.451985  0.903970  0.000000   \n",
      "while       0.000000  0.000000  0.000000  0.000000  0.000000  1.704748   \n",
      "who         0.451985  0.000000  0.451985  0.000000  0.451985  0.000000   \n",
      "why         1.011601  0.000000  0.000000  0.000000  1.011601  1.011601   \n",
      "wide        0.000000  2.397895  0.000000  0.000000  0.000000  0.000000   \n",
      "will        0.903970  0.903970  0.903970  0.451985  0.451985  0.000000   \n",
      "wish        0.000000  0.000000  0.000000  0.000000  0.000000  2.397895   \n",
      "with        0.381241  0.095310  0.095310  0.285931  0.190620  0.285931   \n",
      "without     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "word        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "work        0.000000  0.606136  0.606136  0.606136  0.000000  0.606136   \n",
      "working     1.299283  0.000000  0.000000  0.000000  0.000000  1.299283   \n",
      "works       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "world       0.606136  1.212272  0.000000  0.606136  0.000000  0.606136   \n",
      "would       0.000000  0.000000  0.788457  1.576915  3.942287  0.000000   \n",
      "write       0.000000  0.000000  0.000000  0.000000  2.397895  0.000000   \n",
      "writing     0.000000  0.000000  0.000000  0.000000  2.397895  0.000000   \n",
      "wrong       0.000000  0.000000  0.000000  0.000000  0.000000  2.397895   \n",
      "years       0.000000  2.397895  0.000000  0.000000  0.000000  0.000000   \n",
      "you         0.000000  0.000000  0.000000  0.000000  3.034803  2.023202   \n",
      "\n",
      "                 tf7       tf8       tf9      tf10      tf11  \n",
      "&           0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "-           0.000000  0.000000  1.299283  0.000000  0.000000  \n",
      "1           1.704748  0.000000  0.000000  0.000000  0.000000  \n",
      "10          0.000000  0.000000  0.000000  0.000000  2.397895  \n",
      "15          0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "190000      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2           2.397895  0.000000  0.000000  0.000000  0.000000  \n",
      "2018        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "21st        2.397895  0.000000  0.000000  0.000000  0.000000  \n",
      "25          0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3           2.397895  0.000000  0.000000  0.000000  0.000000  \n",
      "50          0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "a           0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "abandon     0.000000  0.000000  0.000000  2.397895  0.000000  \n",
      "abilities   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "about       1.273815  0.955361  0.636907  0.000000  0.636907  \n",
      "academic    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "accomplish  0.000000  0.000000  0.000000  2.397895  0.000000  \n",
      "according   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "achieve     0.000000  2.397895  0.000000  0.000000  0.000000  \n",
      "acquire     0.000000  1.704748  0.000000  0.000000  0.000000  \n",
      "actionable  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "activities  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "activity    0.000000  0.000000  0.788457  0.788457  0.000000  \n",
      "actual      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "actually    2.023202  0.000000  1.011601  0.000000  0.000000  \n",
      "addition    0.000000  2.397895  0.000000  0.000000  0.000000  \n",
      "ads         2.397895  0.000000  0.000000  0.000000  0.000000  \n",
      "advising    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "affected    0.000000  0.000000  2.397895  0.000000  0.000000  \n",
      "...              ...       ...       ...       ...       ...  \n",
      "weeks       0.000000  0.000000  0.000000  0.000000  1.704748  \n",
      "weigh       0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "well        0.000000  1.011601  2.023202  0.000000  0.000000  \n",
      "went        0.000000  0.000000  0.000000  4.795791  0.000000  \n",
      "were        0.000000  0.606136  1.212272  0.000000  0.000000  \n",
      "what        0.636907  0.318454  0.318454  0.955361  0.000000  \n",
      "what's      1.704748  0.000000  0.000000  0.000000  0.000000  \n",
      "when        0.000000  2.598566  1.299283  1.299283  0.000000  \n",
      "where       0.000000  0.000000  0.000000  0.000000  2.397895  \n",
      "whether     0.000000  0.000000  4.795791  0.000000  0.000000  \n",
      "which       0.451985  0.000000  0.451985  1.355955  0.000000  \n",
      "while       1.704748  0.000000  0.000000  0.000000  0.000000  \n",
      "who         0.451985  0.000000  0.903970  1.355955  0.903970  \n",
      "why         0.000000  0.000000  0.000000  3.034803  0.000000  \n",
      "wide        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "will        0.000000  0.903970  0.451985  0.000000  0.000000  \n",
      "wish        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "with        0.000000  0.285931  0.571861  0.190620  0.095310  \n",
      "without     0.000000  0.000000  2.397895  0.000000  0.000000  \n",
      "word        2.397895  0.000000  0.000000  0.000000  0.000000  \n",
      "work        0.000000  0.606136  0.000000  0.000000  0.606136  \n",
      "working     0.000000  0.000000  1.299283  0.000000  0.000000  \n",
      "works       0.000000  0.000000  0.000000  0.000000  2.397895  \n",
      "world       0.000000  0.000000  0.000000  0.606136  0.606136  \n",
      "would       0.000000  1.576915  0.000000  0.000000  3.942287  \n",
      "write       0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "writing     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "wrong       0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "years       0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "you         0.000000  3.034803  1.011601  0.000000  0.000000  \n",
      "\n",
      "[971 rows x 11 columns]\n",
      "0.903970247486\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "term_idf = df.astype(bool).sum(axis=1)  # get the number of which frequency is not 0 in every row\n",
    "\n",
    "idf = pd.DataFrame({k : [math.log(11/v)] for (k,v) in term_idf.items()})  # build the dataframe\n",
    "idf = idf.T  # switch column and rows\n",
    "idf.columns = ['idf']  # remane column as \"idf\"\n",
    "print(idf)\n",
    "\n",
    "tfidf = pd.DataFrame(df.values*idf.values, columns=df.columns, index=df.index)  # build TF-IDF data frame\n",
    "print(tfidf)\n",
    "\n",
    "tfidf.to_csv('tfidf.txt', index=True, sep='\\t', header=True, mode = 'a')  # output as text file\n",
    "\n",
    "def returnTFIDF (term, document):  #  a program of \"returnTFIDF\"\n",
    "    TFIDF = tfidf.loc[str(term), str(document)]\n",
    "    print(TFIDF)\n",
    "    \n",
    "returnTFIDF ('will', 'tf1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Extra Credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'in': 6\n",
      "'the': 24\n",
      "'first': 1\n",
      "'week's': 1\n",
      "'cls': 7\n",
      "'we': 7\n",
      "'introduce': 1\n",
      "'ourselves': 1\n",
      "'and': 17\n",
      "'reon': 1\n",
      "'of': 13\n",
      "'picking': 1\n",
      "'th': 4\n",
      "'after': 3\n",
      "'dr': 2\n",
      "'rhed': 2\n",
      "'iqbal': 2\n",
      "'introduced': 1\n",
      "'main': 1\n",
      "'contents': 1\n",
      "'i': 9\n",
      "'felt': 1\n",
      "'really': 5\n",
      "'interested': 2\n",
      "'job': 1\n",
      "'market': 2\n",
      "'how': 1\n",
      "'to': 5\n",
      "'become': 2\n",
      "'a': 7\n",
      "'data': 7\n",
      "'scientt': 2\n",
      "'also': 1\n",
      "'found': 3\n",
      "'examples': 1\n",
      "'ce': 1\n",
      "'studies': 1\n",
      "'would': 2\n",
      "'be': 2\n",
      "'interesting': 3\n",
      "'help': 2\n",
      "'me': 1\n",
      "'lot': 2\n",
      "'learn': 1\n",
      "'python': 2\n",
      "'then': 1\n",
      "'told': 1\n",
      "'us': 2\n",
      "'something': 1\n",
      "'about': 2\n",
      "'f': 2\n",
      "'science': 4\n",
      "'professionals': 1\n",
      "'he': 2\n",
      "'gave': 1\n",
      "'brief': 2\n",
      "'introduction': 3\n",
      "'mgan': 1\n",
      "'stanley': 1\n",
      "'ironwood': 1\n",
      "'airbnb': 1\n",
      "'dcussed': 2\n",
      "'relationship': 1\n",
      "'between': 3\n",
      "'economy': 1\n",
      "'regard': 1\n",
      "'demand': 1\n",
      "'most': 1\n",
      "'part': 1\n",
      "'keep': 1\n",
      "'believing': 1\n",
      "'truth': 2\n",
      "'wld': 1\n",
      "'our': 2\n",
      "'society': 2\n",
      "'behind': 1\n",
      "'which': 1\n",
      "'hardly': 1\n",
      "'meure': 1\n",
      "'understand': 2\n",
      "'befe': 2\n",
      "'use': 1\n",
      "'analyze': 1\n",
      "'programs': 1\n",
      "'with': 3\n",
      "'r': 1\n",
      "'other': 1\n",
      "'computer': 2\n",
      "'languages': 1\n",
      "'dcover': 1\n",
      "'grow': 1\n",
      "'nowadays': 1\n",
      "'out': 2\n",
      "'my': 1\n",
      "'project': 1\n",
      "'group': 1\n",
      "'began': 1\n",
      "'activity': 1\n",
      "'determining': 1\n",
      "'application': 2\n",
      "'meuring': 1\n",
      "'silarity': 1\n",
      "'different': 1\n",
      "'people': 1\n",
      "'progression': 1\n",
      "'helpful': 1\n",
      "'dcuss': 1\n",
      "'topics': 1\n",
      "'others': 1\n",
      "'their': 1\n",
      "'unique': 1\n",
      "'thoughts': 1\n",
      "'are': 1\n",
      "'dividing': 1\n",
      "'students': 2\n",
      "'into': 1\n",
      "'groups': 1\n",
      "'four': 1\n",
      "'have': 2\n",
      "'infmation': 1\n",
      "'on': 1\n",
      "'students'': 1\n",
      "'gpa': 1\n",
      "'lt': 1\n",
      "'semester': 1\n",
      "'graduate': 1\n",
      "'courses': 1\n",
      "'taken': 1\n",
      "'need': 1\n",
      "'fmula': 1\n",
      "'evaluate': 1\n",
      "'difference': 1\n",
      "'skill': 1\n",
      "'levels': 1\n",
      "'finh': 1\n",
      "'wk': 1\n",
      "'together': 1\n",
      "'modules': 1\n",
      "'course': 1\n",
      "'look': 1\n",
      "'fward': 1\n",
      "'machine': 1\n",
      "'learning': 2\n",
      "'deep': 1\n",
      "'will': 1\n",
      "'future': 2\n",
      "'know': 1\n",
      "'nothing': 1\n",
      "'sentent': 1\n",
      "'analys': 1\n",
      "'vualization': 1\n",
      "'now': 1\n",
      "'i'm': 1\n",
      "'these': 1\n",
      "'two': 1\n",
      "'area': 1\n",
      "'feel': 1\n",
      "'it': 1\n",
      "'signifit': 1\n",
      "            tf1  tf2  tf3  tf4  tf5  tf6  tf7  tf8  tf9  tf10  tf11\n",
      "&             0    0    1    0    0    0    0    0    0     0     0\n",
      "'s            0    0    0    0    0    1    1    0    0     0     0\n",
      "-             0    0    0    0    2    2    0    0    1     0     0\n",
      "1             0    0    1    0    0    0    1    0    0     0     0\n",
      "10            0    0    0    0    0    0    0    0    0     0     1\n",
      "15            1    0    0    0    1    0    0    0    0     0     0\n",
      "190000        1    0    0    0    1    0    0    0    0     0     0\n",
      "2             0    0    0    0    0    0    1    0    0     0     0\n",
      "2018          1    0    0    0    1    0    0    0    0     0     0\n",
      "21st          0    0    0    0    0    0    1    0    0     0     0\n",
      "25            0    2    0    0    0    0    0    0    0     0     0\n",
      "3             0    0    0    0    0    0    1    0    0     0     0\n",
      "50            0    1    0    0    0    0    0    0    0     0     0\n",
      ";             0    0    0    0    0    0    1    0    0     0     0\n",
      "a            10   10    8    7   13    8   10    9    8    13     3\n",
      "abandon       0    0    0    0    0    0    0    0    0     1     0\n",
      "abilities     2    0    0    0    0    0    0    0    0     0     0\n",
      "about         0    1    1    2    0    2    4    3    2     0     2\n",
      "academic      0    0    0    0    1    0    0    0    0     0     0\n",
      "accding       0    1    0    0    1    0    0    0    0     0     0\n",
      "accomplh      0    0    0    0    0    0    0    0    0     1     0\n",
      "achieve       0    0    0    0    0    0    0    1    0     0     0\n",
      "acquire       0    0    0    0    0    1    0    1    0     0     0\n",
      "actionable    1    0    0    0    1    0    0    0    0     0     0\n",
      "activities    0    1    0    0    0    0    0    0    0     0     0\n",
      "activity      0    1    0    1    0    2    0    0    1     1     0\n",
      "actual        0    1    1    0    0    0    0    0    0     0     0\n",
      "actually      0    1    0    0    1    0    2    0    1     0     0\n",
      "addition      0    0    0    0    0    0    0    1    0     0     0\n",
      "ads           0    0    0    0    0    0    1    0    0     0     0\n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...\n",
      "website       0    0    0    0    0    1    0    0    0     0     0\n",
      "websites      0    0    0    0    0    0    0    0    0     1     0\n",
      "week's        0    0    0    1    0    0    0    0    0     0     0\n",
      "weeks         0    1    0    0    0    0    0    0    0     0     1\n",
      "weigh         0    0    1    0    0    0    0    0    0     0     0\n",
      "well          2    1    0    0    0    0    0    1    2     0     0\n",
      "went          0    0    0    0    0    0    0    0    0     2     0\n",
      "were          0    1    1    0    1    1    0    1    2     0     0\n",
      "wh            0    0    0    0    0    1    0    0    0     0     0\n",
      "when          0    0    0    0    0    0    0    2    1     1     0\n",
      "where         0    0    0    0    0    0    0    0    0     0     1\n",
      "whether       0    0    0    0    0    0    0    0    2     0     0\n",
      "which         0    3    1    1    2    0    1    0    1     3     0\n",
      "while         0    0    0    0    0    1    1    0    0     0     0\n",
      "who           1    0    1    0    1    0    1    0    2     3     2\n",
      "why           1    0    0    0    1    1    0    0    0     3     0\n",
      "wide          0    1    0    0    0    0    0    0    0     0     0\n",
      "will          2    2    2    1    1    0    0    2    1     0     0\n",
      "with          4    1    1    3    2    3    0    3    6     2     1\n",
      "without       0    0    0    0    0    0    0    0    1     0     0\n",
      "wk            0    1    1    1    0    1    0    1    0     0     1\n",
      "wking         1    0    0    0    0    1    0    0    1     0     0\n",
      "wks           0    0    0    0    0    0    0    0    0     0     1\n",
      "wld           1    2    0    1    0    1    0    0    0     1     1\n",
      "would         0    0    1    2    5    0    0    2    0     0     5\n",
      "write         0    0    0    0    1    0    0    0    0     0     0\n",
      "writing       0    0    0    0    1    0    0    0    0     0     0\n",
      "wrong         0    0    0    0    0    1    0    0    0     0     0\n",
      "years         0    1    0    0    0    0    0    0    0     0     0\n",
      "you           0    0    0    0    3    2    0    3    1     0     0\n",
      "\n",
      "[956 rows x 11 columns]\n",
      "[[0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with open('LSA.txt', 'r') as f:\n",
    "    data = f.read().lower()\n",
    "    clean_data = re.sub(r'[,\"./()?:!]', '', data)\n",
    "\n",
    "blacklist = [\"as\", \"is\", \"im\", \"or\", \"they\", \"those\", \"what\", \"this\", \"that\", \"can\"]  # Blacklist of words to be filtered out\n",
    "for word in blacklist:\n",
    "    clean_data = clean_data.replace(word, \"\")\n",
    "    \n",
    "    result = {}\n",
    "    for line in clean_data.splitlines():\n",
    "        if not line:\n",
    "            continue  # skip blank lines\n",
    "        elif line.startswith('xxx'):\n",
    "            doc_num = 'tf{}'.format(line[3:])  # skip the \"XXX\" and name the docs as \"tf1 - tf11\"\n",
    "        else:\n",
    "            result[doc_num] = collections.Counter(line.split())\n",
    " \n",
    "    list(result.keys())\n",
    "\n",
    "for k, v in list(result['tf4'].items()):  # select any dicts from result to see if it is correct\n",
    "    print(\"'{}': {}\".format(k, v))\n",
    "    \n",
    "df = pd.DataFrame(result, columns = list(result.keys()))\n",
    "df = df.fillna(0).astype(int)\n",
    "\n",
    "print(df)  # see the TD - Term Frequency data frame we get\n",
    "\n",
    "# df.to_csv('tdm.txt', index=True, sep='\\t', header=True, mode = 'a')  # output as text file\n",
    "\n",
    "np_df = df.as_matrix()  # if we wanna turn it into a numpy matrix\n",
    "print(np_df)\n",
    "\n",
    "def returnTermFrequency (term, document):  #  a program of \"returnTermFrequency\"\n",
    "    TermFrequency = df.loc[str(term), str(document)]\n",
    "    print(TermFrequency)\n",
    "    \n",
    "returnTermFrequency ('will', 'tf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ffd2ea14255c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ffd2ea14255c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    lsa_Wang.ipynb Download as python(.py)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lsa_Wang.ipynb Download as python(.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
